{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import pandas as pd\n",
    "from pyspark.sql import Row\n",
    "import sys\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta as rl\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import traceback\n",
    "from threading import Thread, Event\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = False\n",
    "parallel_pipes = []\n",
    "\n",
    "user_id = '0b18fb23-a68c-4072-ae7d-7a0fee6a184e'\n",
    "project_id = 'd79a923b-8d76-481d-9a18-fddf9dbd0a57'\n",
    "\n",
    "\n",
    " \n",
    "#Current folder path\n",
    "#json_data_path = '/bigbrain/bb-admin/controller/data/kerbros_cron/li_prod/' \n",
    "json_data_path = str(os.getcwd())+'/'\n",
    "\n",
    "header = {\n",
    "    \"X-Consumer-Custom-ID\": user_id,\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "ip = \"10.9.106.143\"\n",
    "port = \"8081\"\n",
    "\n",
    "base_url = f\"http://{ip}:{port}/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: Production Pipeline-Final\n",
      "200\n",
      "<Response [200]>\n",
      " Status for pipeline: Production Pipeline-Final is FAILED\n",
      "Done {'status': 'FAILED', 'runNumber': 'Run 511', 'block_name': 'NAS Reader', 'error': '', 'traceback': ''}\n"
     ]
    }
   ],
   "source": [
    "def trigger_pipeline(trigger_api_url, file_name):\n",
    "    output = {\n",
    "        'result': '',\n",
    "        'error': '',\n",
    "        'traceback': ''\n",
    "    }\n",
    "    try:\n",
    "        data_path = json_data_path + file_name\n",
    "        url = base_url + trigger_api_url\n",
    "        res = requests.post(url=url, data=json.dumps(json.load(open(data_path))), headers=header)\n",
    "        print(str(res.status_code))\n",
    "        print(str(res))\n",
    "        output['result']=res.json()\n",
    "        return output\n",
    "    except Exception as e:\n",
    "        output['error'] = \"Error while triggering pipeline: \" + str(e)\n",
    "        output['traceback'] = str(traceback.format_exc())\n",
    "        print(f\"Error: {str(e)} \\n trace: {traceback.format_exc()}\")\n",
    "        return output\n",
    "        \n",
    "\n",
    "\n",
    "def get_status(run_id, retry=10):\n",
    "    output = {\n",
    "        'result': '',\n",
    "        'error': '',\n",
    "        'traceback': ''\n",
    "    }\n",
    "    try:\n",
    "        url = f\"{base_url}/bigbrain/engine/run_view/{project_id}/pipeline/run-id/run-details?runId={run_id}\"\n",
    "        res = requests.get(url, headers=header)\n",
    "        output['result']=res.json()\n",
    "        return output\n",
    "    except Exception as e:\n",
    "        output['error'] = \"Error while getting status of pipeline: \" + str(e)\n",
    "        output['traceback'] = str(traceback.format_exc())\n",
    "        print(f\"Error: {str(e)} \\n trace: {traceback.format_exc()}\")\n",
    "\n",
    "\n",
    "def check_status(run_id, name):\n",
    "    output = {\n",
    "        'status': '',\n",
    "        'runNumber': '',\n",
    "        'block_name': '',\n",
    "        'error': '',\n",
    "        'traceback': ''\n",
    "    }\n",
    "    time.sleep(10)\n",
    "    retry = 5\n",
    "    while True:\n",
    "        try:\n",
    "            time.sleep(300) #Check status for every 5min\n",
    "            res = get_status(run_id)\n",
    "            if res['result']['status'] == 'SUCCESS':\n",
    "                if res['result']['result']['status'] == 'COMPLETED':\n",
    "                    stat=f\" Status for pipeline: {name} is {res['result']['result']['status']}\"\n",
    "                    print(stat)\n",
    "                    output['status'] = res['result']['result']['status']\n",
    "                    output['runNumber'] = 'Run '+ str(res['result']['result']['runNumber'])\n",
    "                    return output\n",
    "                elif res['result']['result']['status'] in ['IN_PROGRESS', 'YET_TO_START']:\n",
    "                    continue\n",
    "                elif res['result']['result']['status'] in ['STOPPED']:\n",
    "                    stat=f\" Status for pipeline: {name} is {res['result']['status']}\"\n",
    "                    print(stat)\n",
    "                    output['status'] = res['result']['result']['status']\n",
    "                    output['runNumber'] = 'Run '+ str(res['result']['result']['runNumber'])\n",
    "                    return output\n",
    "                else:\n",
    "                    failed = True\n",
    "                    stat=f\" Status for pipeline: {name} is {res['result']['result']['status']}\"\n",
    "                    print(stat)\n",
    "                    output['status'] = res['result']['result']['status']\n",
    "                    output['runNumber'] = 'Run '+ str(res['result']['result']['runNumber'])\n",
    "                    if 'blockRunDetails' in res['result']['result']:\n",
    "                        for obj in res['result']['result']['blockRunDetails']:\n",
    "                            x = res['result']['result']['blockRunDetails'][obj]\n",
    "                            if x['status'] == 'FAILED':\n",
    "                                output['block_name'] = x['stageName']\n",
    "                    return output\n",
    "            else:\n",
    "                retry = retry - 1\n",
    "                if retry<1:\n",
    "                    output['error'] == res['result']['result']\n",
    "                    return output\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)} \\n trace: {traceback.format_exc()}\")\n",
    "            retry = retry - 1\n",
    "            if retry<1:\n",
    "                output['error'] = \"Error while getting status of pipeline: \" + str(e)\n",
    "                output['traceback'] = str(traceback.format_exc())\n",
    "                return output\n",
    "\n",
    "\n",
    "# Run parallel Pipelines\n",
    "\n",
    "def run_pipeline(req):\n",
    "    output = {\n",
    "        'status': '',\n",
    "        'error': '',\n",
    "        'traceback': ''\n",
    "    }\n",
    "    try:\n",
    "        if failed is True:\n",
    "            print(f\"Skipping Run: {req['name']}\")\n",
    "            return\n",
    "        print(f\"Running: {req['name']}\")\n",
    "        tr_res = trigger_pipeline(req['trigger_url'], req['data'])\n",
    "        if 'result' in tr_res:\n",
    "            if 'result' in tr_res['result']:\n",
    "                if 'id' in tr_res['result']['result']:\n",
    "                    run_id = tr_res['result']['result']['id']\n",
    "                    if run_id:\n",
    "                        req['run_id'] = run_id\n",
    "                        # monitor pipeline till it gets completed\n",
    "                        stat_res=check_status(run_id, req['name'])\n",
    "                        return stat_res\n",
    "                else:\n",
    "                    print(tr_res)\n",
    "                    output['status'] = 'ERROR'\n",
    "                    output['error'] = 'Error while triggering pipeline: ' + tr_res['result']['result']\n",
    "                    output['traceback'] = tr_res['traceback']\n",
    "                    return output\n",
    "            else:\n",
    "                output['status'] = 'ERROR'\n",
    "                output['error'] = tr_res['error']\n",
    "                output['traceback'] = tr_res['traceback']\n",
    "                return output\n",
    "        else:\n",
    "            output['status'] = 'ERROR'\n",
    "            output['error'] = \"Something wrong with run check logs!!\"\n",
    "            return output\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        output['status'] = 'ERROR'\n",
    "        output['error'] = 'Error while triggering pipeline: ' + tr_res['result']['result']\n",
    "        output['traceback'] = tr_res['traceback']\n",
    "        return output\n",
    "    finally:\n",
    "        if req in parallel_pipes:\n",
    "            parallel_pipes.remove(req)\n",
    "\n",
    "\n",
    "pipelines_details = [\n",
    "    {\n",
    "        \"name\": \"Production Pipeline-Final\",\n",
    "        \"trigger_url\": \"/bigbrain/engine/run_view/pipeline/batch/api-trigger?apiLinkUUID=991e49ba-3f8a-4626-9e9b-92d6062e3f30\",\n",
    "        \"execution\": \"parallel\",\n",
    "        \"data\": \"fx_churn.json\",\n",
    "        \"skip\": True\n",
    "    },{\n",
    "        \"name\": \"Production Pipeline-Final\",\n",
    "        \"trigger_url\": \"/bigbrain/engine/run_view/pipeline/batch/api-trigger?apiLinkUUID=38a84608-2125-428d-b853-a0016c1c1be8\",\n",
    "        \"execution\": \"parallel\",\n",
    "        \"data\": \"fx_churn.json\",\n",
    "        \"skip\": False\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "stat_res=run_pipeline(pipelines_details[1])\n",
    "stat = stat_res['status']\n",
    "print('Done', stat_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'FAILED', 'block_name': 'NAS Reader', 'error': '', 'traceback': ''}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating spark session ##\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Corporate Forex Churn Prediction Mail Automation Script\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('202008', 'Aug')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Getting todays date ##\n",
    "\n",
    "today = dt.date.today()\n",
    "month=dt.datetime.strftime(today,'%Y')+dt.datetime.strftime(today,'%m')\n",
    "month2=dt.datetime.strftime(today,'%b')\n",
    "month,month2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Final HIVE tables in BDL PROD where output of RZT pipeline is stored ##\n",
    "\n",
    "table_name_high='test_high'\n",
    "table_name_low='test_low'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15339, 38412)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Getting todays count from final tables ##\n",
    "\n",
    "high_count=spark.sql(\"select count(*) from usecase_common.{} where month_period={}\".format(table_name_high,month)).collect()[0][0]\n",
    "low_count=spark.sql(\"select count(*) from usecase_common.{} where month_period={}\".format(table_name_low,month)).collect()[0][0]\n",
    "high_count,low_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# me == my email address\n",
    "# you == recipient's email address\n",
    "#me = \"akash1.agarwal@axisbank.com\"\n",
    "me = \"177724@axisbank.com\"\n",
    "you = [\"177724@axisbank.com\"]\n",
    "cc = [\"177724@axisbank.com\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create message container - the correct MIME type is multipart/alternative.\n",
    "\n",
    "msg = MIMEMultipart('alternative')\n",
    "msg['Subject'] = \"RZT Pipeline Status Email : Corporate Forex churn Predictions \" + \"<\" + today.strftime('%d%B%Y') + \">\"\n",
    "msg['From'] = me\n",
    "msg['To'] = \", \".join(you)\n",
    "msg['Cc'] = \", \".join(cc)\n",
    "\n",
    "# Create the body of the message (a plain-text and an HTML version).\n",
    "html = \"\"\"\\\n",
    "<html>\n",
    "  <head></head>\n",
    "  <body>\n",
    " <h1>\n",
    "        <font color=\"black\">RZT Pipeline for Cororate Forex Churn Status</font></h1><br>\n",
    "        <p style = \"font-family: calibri; font-size: 14pt; font-style: calibri; font-weight: normal; text-align: left\">Status of RZT Pipeline for {} month is {}.<br><br>Data Count of each of the segment is below:<br><br>HIGH : {}<br>LOW: {}<br></p>\n",
    " </body>\n",
    "</html>\n",
    "\"\"\".format(month2,stat,high_count,low_count)\n",
    "\n",
    "# Record the MIME types of one part - text/html.\n",
    "part2 = MIMEText(html, 'html')\n",
    "\n",
    "# Attach parts into message container.\n",
    "# According to RFC 2046, the last part of a multipart message, in this case\n",
    "# the HTML message, is best and preferred.\n",
    "\n",
    "msg.attach(part2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221, b'2.0.0 Bye')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Send the message via local SMTP server.\n",
    "\n",
    "s = smtplib.SMTP('10.9.9.28', 2255)\n",
    "s.ehlo()\n",
    "\n",
    "s.sendmail(me, you + cc, msg.as_string())\n",
    "s.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stoping the spark session ##\n",
    "\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
