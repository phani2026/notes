{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['APP_HOST'] = 'http://192.168.60.25:8005'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't setup user context. You may not be running this in the platform's Jupyter\n",
      "Failed to load configuration file. Using default configs\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from abc import abstractmethod\n",
    "from razor import inputs,outputs,Block,Pipeline\n",
    "from razor.core.blocks.models import ModelBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a ML Model\n",
    "\n",
    "#### Problem \n",
    "You want to create a ML model. For example, there is a dataset on which you want to build a classifier model using logistic regression. \n",
    "\n",
    "\n",
    "#### Solution\n",
    "Create a Model Block for LogisticRegression which will perform the logistic regression operation\n",
    "\n",
    "<i><u>Example</u></i><br/>\n",
    "1. Create a generic classifer block to handle the training and inference of a model\n",
    "    * `fit` - This function contains the logic needed to train the model\n",
    "    * `Evaluate` - This function contains the logic needed to evaluate the model using test datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "class Classifier(ModelBlock):\n",
    "\n",
    "    @abstractmethod\n",
    "    def create_model(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Should create and return the model object\n",
    "        \"\"\"\n",
    "    @abstractmethod\n",
    "    def attribute_func(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Should return the attribute values\n",
    "        \"\"\"\n",
    "        \n",
    "    @abstractmethod\n",
    "    def operation_func(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Should return the operation reuslts\n",
    "        \"\"\"\n",
    "\n",
    "    def load_saved_model(self, path):\n",
    "        self.model = pickle.load(open(self.save_path(path=path), 'rb'))\n",
    "\n",
    "    def save_model(self, path):\n",
    "        pickle.dump(self.model, open(self.save_path(path=path), 'wb'))\n",
    "\n",
    "    def persist_train(self, x_data, y_data, path):\n",
    "        self.load_saved_model(path)\n",
    "        self.fit(x_data, y_data)\n",
    "\n",
    "    def transform(self, x_data, predictions):\n",
    "        predictions.put(self.model.predict(x_data))\n",
    "        \n",
    "        \n",
    "    def fit(self, x_data, y_data, test_x_data, test_y_data, metric_function, average, operation, predictions, attribute, model_attributes, path):\n",
    "        if path is not None and len(path) != 0:\n",
    "            try:\n",
    "                self.load_saved_model(path)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        pred = self.operation_func(x_data=x_data, y_data=y_data, test_x_data=test_x_data, test_y_data=test_y_data,\n",
    "                                   operation=operation, metric_function=metric_function, average=average)\n",
    "        predictions.put([pred] if isinstance(pred, (int, float, str)) else pred)\n",
    "\n",
    "        k = self.model\n",
    "        if attribute is not None and len(attribute) != 0:\n",
    "            attr_value = self.attribute_func(attribute)\n",
    "            print(f\"{attribute}: \", attr_value)\n",
    "            model_attributes.put([attr_value] if isinstance(attr_value, (int, float, str)) else attr_value)\n",
    "            \n",
    "        if all(v is not None for v in [x_data, y_data]) or all(v is not None for v in [test_x_data, test_y_data]) and operation != \"evaluate\":\n",
    "            if test_x_data is None:\n",
    "                test_x_data, test_y_data = x_data, y_data\n",
    "            self.evaluate(test_x_data, test_y_data, metric_function, average)\n",
    "\n",
    "\n",
    "    def evaluate(self, test_x_data, test_y_data, metric_function, average):\n",
    "        metric_func = {\"accuracy_score\": metrics.accuracy_score,\n",
    "                       \"precision_score\": metrics.precision_score,\n",
    "                       \"recall_score\": metrics.recall_score,\n",
    "                       \"f1_score\": metrics.f1_score,\n",
    "                       \"confusion_matrix\": metrics.confusion_matrix}\n",
    "        metric_function = [metric_function] if not isinstance(metric_function, list) else metric_function\n",
    "        final_metrics = []\n",
    "        for _metric_function in metric_function:\n",
    "            eval_metric = metric_func.get(_metric_function, None)\n",
    "            if _metric_function not in [\"accuracy_score\", \"confusion_matrix\"]:\n",
    "                _metric_value = eval_metric(test_y_data, self.model.predict(test_x_data), average=average)\n",
    "            else:\n",
    "                _metric_value = eval_metric(test_y_data, self.model.predict(test_x_data))\n",
    "            print(f'{_metric_function}: ', _metric_value)\n",
    "            final_metrics.append(_metric_value)\n",
    "\n",
    "        return (final_metrics if len(final_metrics) > 1 else final_metrics[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create an instance of `LogisticRegression` class with following parameters and train the model by invoking execute():\n",
    "\n",
    "    * `penalty` - Specify the norm used in the penalization (default= 'l2').\n",
    "    * `tol` - Specify tolerance for stopping criteria (default=0.0001).\n",
    "    * `C` - Specify regularization parameter (default=1.0).\n",
    "    * `class_weight` - Weightage to be given to each class in the data (default=None).\n",
    "    * `random_state` - Seed value of the random number generator (default=None).\n",
    "    * `solver` - Specify optimization algorithm to use (default='lbfgs').\n",
    "    * `max_iter` - Maximum iterations for the solvers to converge (default=100).\n",
    "    * `n_jobs` - Specify number of CPU cores to be used when parallelizing (default=None).\n",
    "    * `x_data` - Data on which the model is to be trained.\n",
    "    * `y_data` - Target values corresponding to each data point in train data.\n",
    "    * `test_x_data` - Test data on which the model is to be evaluated.\n",
    "    * `test_y_data` - Test target values corresponding to each data point in `test_x_data`.\n",
    "    * `operation` - Defines what operation to perform.\n",
    "         * For training model - `fit`\n",
    "         * For Predicting model - `predict`\n",
    "         * For evaluating model - `evaluate`\n",
    "    * `attribute` - Specify suitable attribute from the following, to be found from the trained model.<br>\n",
    "         `classes_`, `coef_`, `intercept_`, `n_iter_`\n",
    "    * `metric_function` - Specify suitable evaluation metric from the folloeing, that best suits for the problem that you are dealing with.\n",
    "         `confusion_matrix`, `accuracy_score`, `precision_score`, `recall_score`, `f1_score`, `roc_curve` \n",
    "    * `path` - Specify the path where the trained model is to be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as Logrec\n",
    "\n",
    "@inputs.atomic.generic('penalty', doc=\"{‘l1’, ‘l2’, ‘elasticnet’, ‘none’}\", default= 'l2')\n",
    "@inputs.atomic.generic('dual', default=False)\n",
    "@inputs.atomic.generic('tol', default=0.0001)\n",
    "@inputs.atomic.generic('C', default=1.0)\n",
    "@inputs.atomic.generic('fit_intercept', default=True)\n",
    "@inputs.atomic.generic('intercept_scaling', default=1)\n",
    "@inputs.atomic.generic('class_weight', default=None)\n",
    "@inputs.atomic.generic('random_state', default=None)\n",
    "@inputs.atomic.generic('solver', default='lbfgs')\n",
    "@inputs.atomic.generic('max_iter', default=100)\n",
    "@inputs.atomic.generic('multi_class', default='auto')\n",
    "@inputs.atomic.generic('verbose', default=0)\n",
    "@inputs.atomic.generic('warm_start', default=False)\n",
    "@inputs.atomic.generic('n_jobs', default=None)\n",
    "@inputs.atomic.generic('l1_ratio', default=None)\n",
    "@inputs.atomic.generic('mode', default=\"FIT\")\n",
    "@inputs.atomic.generic('operation', default=\"fit\",\n",
    "                       doc=\"fit, decision_function, densify, predict, predict_proba, predict_log_proba, sparsify, evaluate, score\",\n",
    "                       required=True)\n",
    "@inputs.atomic.generic('attribute', default=None,\n",
    "                       doc=\"classes_, coef_, intercept_, n_iter_\")\n",
    "@inputs.atomic.generic(\"x_data\")\n",
    "@inputs.atomic.generic(\"y_data\")\n",
    "@inputs.atomic.generic(\"test_x_data\", required=False)\n",
    "@inputs.atomic.generic(\"test_y_data\", required=False)\n",
    "@inputs.atomic.generic(\"metric_function\", default=\"accuracy_score\")\n",
    "@inputs.atomic.generic(\"average\", default=\"binary\")\n",
    "@inputs.atomic.generic(\"path\", default=None)\n",
    "@outputs.atomic.generic(\"predictions\")\n",
    "@outputs.atomic.generic(\"model_attributes\")\n",
    "class LogisticRegression(Classifier):\n",
    "    \"\"\"\n",
    "        Logistic Regression from sklearn\n",
    "    \"\"\"\n",
    "    def create_model(self, penalty, dual, tol, C, fit_intercept, intercept_scaling, class_weight, random_state, solver,\n",
    "                     max_iter, multi_class, verbose, warm_start, n_jobs, l1_ratio):\n",
    "        return Logrec(penalty=penalty, dual=dual, tol=tol, C=C, fit_intercept=fit_intercept,\n",
    "                                         intercept_scaling=intercept_scaling, class_weight=class_weight,\n",
    "                                         random_state=random_state, solver=solver,\n",
    "                                         max_iter=max_iter, multi_class=multi_class, verbose=verbose,\n",
    "                                         warm_start=warm_start, n_jobs=n_jobs, l1_ratio=l1_ratio)\n",
    "\n",
    "    def operation_func(self, x_data, y_data, test_x_data, test_y_data, operation, metric_function, average):\n",
    "        func = {\"fit\": self.model.fit, \"decision_function\": self.model.decision_function,\n",
    "                \"predict\": self.model.predict, \"densify\": self.model.densify,\n",
    "                \"predict_log_proba\": self.model.predict_log_proba, \"predict_proba\": self.model.predict_proba,\n",
    "                \"sparsify\": self.model.sparsify, \"score\": self.model.score, \"evaluate\": self.evaluate}\n",
    "\n",
    "        method = func.get(operation, None)\n",
    "        if operation in [\"fit\", \"score\"]:\n",
    "            pred = method(x_data, y_data)\n",
    "        elif operation in [\"decision_function\", \"predict\", \"predict_proba\", \"predict_log_proba\"]:\n",
    "            pred = method(x_data)\n",
    "        elif operation in [\"evaluate\"]:\n",
    "            if test_x_data is None:\n",
    "                test_x_data, test_y_data = x_data, y_data\n",
    "            pred = self.evaluate(test_x_data, test_y_data, metric_function, average)\n",
    "        else:\n",
    "            pred = method()\n",
    "        return pred\n",
    "\n",
    "    def attribute_func(self, attribute):\n",
    "        k = self.model\n",
    "        attr = {\"classes_\": k.classes_, \"coef_\": k.coef_,\n",
    "                \"intercept_\": k.intercept_, \"n_iter_\": k.n_iter_}\n",
    "        attr_value = attr.get(attribute, None)\n",
    "        return attr_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a Train pipeline\n",
    "\n",
    "#### Problem \n",
    "As a user you want to use the logistic regression model in a train pipeline\n",
    "\n",
    "#### Solution\n",
    "The created model block can be used in the pipeline, through which data can be fed and the model can be trained. The following example illustrates a simple pipeline which processes and then trains a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><u>Block 1 - Reads a csv in chunks and gives a series output</u></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@inputs.atomic.generic(\"filepath_or_buffer\", required=True)\n",
    "@inputs.atomic.generic(\"delimiter\", default = None)\n",
    "@inputs.atomic.generic(\"chunk_size\", default=10)\n",
    "@inputs.atomic.generic(\"nrows\", default=None)\n",
    "@outputs.series.generic(\"output\")\n",
    "class CsvReader(Block):\n",
    "    def run(self, filepath_or_buffer, delimiter, chunk_size, nrows, output):\n",
    "        chunks = pd.read_csv(filepath_or_buffer, chunksize=chunk_size, nrows=nrows, delimiter = delimiter)\n",
    "        for df in chunks:\n",
    "            output.put(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><u>Block 2 - Filters out the rows in which Nan is present</u></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@inputs.atomic.generic(\"columns\")\n",
    "@inputs.series.generic(\"df_chunks\", required=True)\n",
    "@outputs.atomic.generic(\"output\")\n",
    "class DfFilterNan(Block):\n",
    "    def run(self, df_chunks, columns, output):\n",
    "        concat_df = pd.DataFrame()\n",
    "        for df in df_chunks:\n",
    "            df.dropna(axis=0, inplace=True)\n",
    "            concat_df = pd.concat([concat_df, df])\n",
    "        output.put(concat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><u>Block 3 - Converts the categorical columns to numerical values</u></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@inputs.atomic.generic(\"columns\")\n",
    "@inputs.atomic.generic(\"df\", required=True)\n",
    "@outputs.atomic.generic(\"output\")\n",
    "class DfCategorical(Block):\n",
    "    def run(self, df, columns, output):\n",
    "        for col in columns:\n",
    "            df[col] = df[col].astype('category')\n",
    "            df[col] = df[col].cat.codes\n",
    "        output.put(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><u> Block 4 - Returns the Features and Labels from a dataframe </u></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@inputs.atomic.generic(\"x_columns\")\n",
    "@inputs.atomic.generic(\"y_column\", default=None)\n",
    "@inputs.atomic.generic(\"df\", required=True)\n",
    "@outputs.atomic.generic(\"out_x\")\n",
    "@outputs.atomic.generic(\"out_y\")\n",
    "class Get_data(Block):\n",
    "    def run(self, df, x_columns, y_column, out_x, out_y):\n",
    "        if y_column is not None and len(y_column)!=0:\n",
    "            x = df[x_columns].values\n",
    "            y = np.squeeze(df[y_column].values)\n",
    "            out_x.put(x)\n",
    "            out_y.put(y)\n",
    "        else:\n",
    "            x = df[x_columns].values\n",
    "            out_x.put(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Defining the Training pipeline</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"372pt\" viewBox=\"0.00 0.00 339.05 372.00\" width=\"339pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 368)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-368 335.05,-368 335.05,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- (LogisticRegression) LogisticRegression_1 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>(LogisticRegression) LogisticRegression_1</title>\n",
       "<ellipse cx=\"163.4\" cy=\"-18\" fill=\"none\" rx=\"118.83\" ry=\"18\" stroke=\"black\"/>\n",
       "<text font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" text-anchor=\"middle\" x=\"163.4\" y=\"-15\">(LogisticRegression) LogisticRegression_1</text>\n",
       "</g>\n",
       "<!-- (Get_data) Get_data_1 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>(Get_data) Get_data_1</title>\n",
       "<ellipse cx=\"163.4\" cy=\"-100\" fill=\"none\" rx=\"68.73\" ry=\"18\" stroke=\"black\"/>\n",
       "<text font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" text-anchor=\"middle\" x=\"163.4\" y=\"-97\">(Get_data) Get_data_1</text>\n",
       "</g>\n",
       "<!-- (Get_data) Get_data_1&#45;&gt;(LogisticRegression) LogisticRegression_1 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>(Get_data) Get_data_1-&gt;(LogisticRegression) LogisticRegression_1</title>\n",
       "<path d=\"M99.64,-93.3C60.05,-88.3 14.43,-79.34 2.06,-64 -8.92,-50.38 26.06,-39.62 66.23,-32.04\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"67.03,-35.46 76.25,-30.24 65.79,-28.57 67.03,-35.46\" stroke=\"black\"/>\n",
       "<text font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" text-anchor=\"middle\" x=\"45.06\" y=\"-56\">out_y-&gt;test_y_data</text>\n",
       "</g>\n",
       "<!-- (Get_data) Get_data_1&#45;&gt;(LogisticRegression) LogisticRegression_1 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>(Get_data) Get_data_1-&gt;(LogisticRegression) LogisticRegression_1</title>\n",
       "<path d=\"M129.78,-84.1C121.91,-78.93 114.53,-72.28 110.06,-64 105.4,-55.36 109.02,-47.69 116.16,-41.23\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"118.36,-43.96 124.3,-35.19 114.18,-38.34 118.36,-43.96\" stroke=\"black\"/>\n",
       "<text font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" text-anchor=\"middle\" x=\"153.06\" y=\"-56\">out_x-&gt;test_x_data</text>\n",
       "</g>\n",
       "<!-- (Get_data) Get_data_1&#45;&gt;(LogisticRegression) LogisticRegression_1 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>(Get_data) Get_data_1-&gt;(LogisticRegression) LogisticRegression_1</title>\n",
       "<path d=\"M182.93,-82.65C187.96,-77.28 192.71,-70.91 195.4,-64 198.12,-57 196.17,-50.06 192.16,-43.81\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"194.67,-41.35 185.66,-35.77 189.23,-45.75 194.67,-41.35\" stroke=\"black\"/>\n",
       "<text font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" text-anchor=\"middle\" x=\"228.22\" y=\"-56\">out_y-&gt;y_data</text>\n",
       "</g>\n",
       "<!-- (Get_data) Get_data_1&#45;&gt;(LogisticRegression) LogisticRegression_1 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>(Get_data) Get_data_1-&gt;(LogisticRegression) LogisticRegression_1</title>\n",
       "<path d=\"M223.24,-91.19C239.18,-86.07 254.66,-77.68 264.4,-64 273.57,-51.11 266.37,-41.86 252.4,-35.24\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"253.49,-31.9 242.9,-31.44 250.89,-38.4 253.49,-31.9\" stroke=\"black\"/>\n",
       "<text font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" text-anchor=\"middle\" x=\"299.22\" y=\"-56\">out_x-&gt;x_data</text>\n",
       "</g>\n",
       "<!-- (DfCategorical) DfCategorical_1 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>(DfCategorical) DfCategorical_1</title>\n",
       "<ellipse cx=\"163.4\" cy=\"-182\" fill=\"none\" rx=\"91.12\" ry=\"18\" stroke=\"black\"/>\n",
       "<text font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" text-anchor=\"middle\" x=\"163.4\" y=\"-179\">(DfCategorical) DfCategorical_1</text>\n",
       "</g>\n",
       "<!-- (DfCategorical) DfCategorical_1&#45;&gt;(Get_data) Get_data_1 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>(DfCategorical) DfCategorical_1-&gt;(Get_data) Get_data_1</title>\n",
       "<path d=\"M163.4,-163.64C163.4,-153.3 163.4,-139.94 163.4,-128.22\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"166.9,-128.05 163.4,-118.05 159.9,-128.05 166.9,-128.05\" stroke=\"black\"/>\n",
       "<text font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" text-anchor=\"middle\" x=\"186.05\" y=\"-138\">output-&gt;df</text>\n",
       "</g>\n",
       "<!-- (DfFilterNan) DfFilterNan_1 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>(DfFilterNan) DfFilterNan_1</title>\n",
       "<ellipse cx=\"163.4\" cy=\"-264\" fill=\"none\" rx=\"79.5\" ry=\"18\" stroke=\"black\"/>\n",
       "<text font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" text-anchor=\"middle\" x=\"163.4\" y=\"-261\">(DfFilterNan) DfFilterNan_1</text>\n",
       "</g>\n",
       "<!-- (DfFilterNan) DfFilterNan_1&#45;&gt;(DfCategorical) DfCategorical_1 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>(DfFilterNan) DfFilterNan_1-&gt;(DfCategorical) DfCategorical_1</title>\n",
       "<path d=\"M163.4,-245.64C163.4,-235.3 163.4,-221.94 163.4,-210.22\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"166.9,-210.05 163.4,-200.05 159.9,-210.05 166.9,-210.05\" stroke=\"black\"/>\n",
       "<text font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" text-anchor=\"middle\" x=\"186.05\" y=\"-220\">output-&gt;df</text>\n",
       "</g>\n",
       "<!-- (CsvReader) CsvReader_1 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>(CsvReader) CsvReader_1</title>\n",
       "<ellipse cx=\"163.4\" cy=\"-346\" fill=\"none\" rx=\"78.73\" ry=\"18\" stroke=\"black\"/>\n",
       "<text font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" text-anchor=\"middle\" x=\"163.4\" y=\"-343\">(CsvReader) CsvReader_1</text>\n",
       "</g>\n",
       "<!-- (CsvReader) CsvReader_1&#45;&gt;(DfFilterNan) DfFilterNan_1 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>(CsvReader) CsvReader_1-&gt;(DfFilterNan) DfFilterNan_1</title>\n",
       "<path d=\"M163.4,-327.64C163.4,-317.3 163.4,-303.94 163.4,-292.22\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"166.9,-292.05 163.4,-282.05 159.9,-292.05 166.9,-292.05\" stroke=\"black\"/>\n",
       "<text font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" text-anchor=\"middle\" x=\"204.68\" y=\"-302\">output-&gt;df_chunks</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv_reader = CsvReader(filepath_or_buffer=\"/myspace/data/titanic/train.csv\")\n",
    "\n",
    "df_filter = (DfFilterNan()\n",
    "            .columns([\"Age\", \"Cabin\"])\n",
    "            .df_chunks(csv_reader.output))\n",
    "\n",
    "df_cat = (DfCategorical()\n",
    "         .columns([\"Sex\", \"Cabin\", \"Embarked\"])\n",
    "         .df(df_filter.output))\n",
    "\n",
    "train_data = (Get_data()\n",
    "             .x_columns(['PassengerId', 'Pclass', 'Sex', 'Age', 'SibSp', 'Fare', 'Cabin', 'Embarked'])\n",
    "             .y_column(['Survived'])\n",
    "             .df(df_cat.output))\n",
    "\n",
    "lr_model_train = (LogisticRegression()\n",
    "         .random_state(111)\n",
    "         .operation(\"fit\")\n",
    "         .x_data(train_data.out_x)\n",
    "         .y_data(train_data.out_y)\n",
    "         .test_x_data(train_data.out_x)\n",
    "         .test_y_data(train_data.out_y)\n",
    "         .attribute(\"n_iter_\")\n",
    "         .path(\"lr_m1.sav\"))\n",
    "\n",
    "train_pipeline = Pipeline(targets=[lr_model_train])\n",
    "train_pipeline.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Executing the training pipeline on local instance</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Executing the training pipeline on Engine </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from razor.platform import engines\n",
    "\n",
    "deployed_pipeline = engines(name='Engine-1').deploy(pipeline=train_pipeline)\n",
    "running_pipeline = deployed_pipeline.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pipeline_run_id': '39a11bcb-b84a-4ad3-a9ba-902ddb520c2c',\n",
       " 'status': 'IN_PROGRESS',\n",
       " 'name': 'Pipeline_1',\n",
       " 'description': '',\n",
       " 'project_id': '862fa216-264c-45c5-b5d0-4e837233367d',\n",
       " 'engine_id': '0e738bcd-b35c-4e6f-b3e2-5d4865406a19',\n",
       " 'deployed_pipeline_id': '26ccec86-c2af-4178-94d4-5631e26c673a',\n",
       " 'block_statuses': {'4405ff72-6191-463b-a737-b7deae5b9973': {'name': 'CsvReader_1',\n",
       "   'status': 'COMPLETED'},\n",
       "  'f5560f94-9b49-4903-b891-1e95f912bac7': {'name': 'DfCategorical_1',\n",
       "   'status': 'YET_TO_START'},\n",
       "  '2d5df01b-4be3-4709-bcc7-1f8c161b4c30': {'name': 'DfFilterNan_1',\n",
       "   'status': 'COMPLETED'}}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_pipeline.status().__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_pipeline.logs(pretty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-54975268b483451aa4e71a7391fa2111\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-54975268b483451aa4e71a7391fa2111\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-54975268b483451aa4e71a7391fa2111\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"vconcat\": [{\"hconcat\": [{\"data\": {\"name\": \"data-7f3b5925e6d1317ce15e5ddbaa67e40f\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"y_label\", \"legend\": {\"columns\": 1, \"orient\": \"bottom\"}}, \"x\": {\"type\": \"temporal\", \"field\": \"x\", \"timeUnit\": \"seconds\", \"title\": \"TIME\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"y\", \"scale\": {\"zero\": false}, \"title\": \"NUMBER OF RECORDS CONSUMED\"}}, \"height\": 300, \"title\": {\"text\": \"IO METRICS of Block: LogisticRegression_1\", \"frame\": \"group\"}, \"width\": 300}, {\"data\": {\"name\": \"data-3528bdcb9f69fa18254afa03aa62cc15\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"y_label\", \"legend\": {\"columns\": 1, \"orient\": \"bottom\"}}, \"x\": {\"type\": \"temporal\", \"field\": \"x\", \"timeUnit\": \"seconds\", \"title\": \"TIME\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"y\", \"scale\": {\"zero\": false}, \"title\": \"NUMBER OF RECORDS CONSUMED / NUMBER OF RECORDS PRODUCED\"}}, \"height\": 300, \"title\": {\"text\": \"IO METRICS of Block: Get_data_1\", \"frame\": \"group\"}, \"width\": 300}, {\"data\": {\"name\": \"data-74f25a3ff4c12b9051d5a4e07e339b7b\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"y_label\", \"legend\": {\"columns\": 1, \"orient\": \"bottom\"}}, \"x\": {\"type\": \"temporal\", \"field\": \"x\", \"timeUnit\": \"seconds\", \"title\": \"TIME\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"y\", \"scale\": {\"zero\": false}, \"title\": \"NUMBER OF RECORDS PRODUCED\"}}, \"height\": 300, \"title\": {\"text\": \"IO METRICS of Block: CsvReader_1\", \"frame\": \"group\"}, \"width\": 300}], \"resolve\": {\"scale\": {\"color\": \"independent\"}}}, {\"hconcat\": [{\"data\": {\"name\": \"data-69317bbe25ddebac43f53e65c89529d0\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"y_label\", \"legend\": {\"columns\": 1, \"orient\": \"bottom\"}}, \"x\": {\"type\": \"temporal\", \"field\": \"x\", \"timeUnit\": \"seconds\", \"title\": \"TIME\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"y\", \"scale\": {\"zero\": false}, \"title\": \"NUMBER OF RECORDS CONSUMED / NUMBER OF RECORDS PRODUCED\"}}, \"height\": 300, \"title\": {\"text\": \"IO METRICS of Block: DfCategorical_1\", \"frame\": \"group\"}, \"width\": 300}, {\"data\": {\"name\": \"data-707ac9f36a02a20861217fdba6fc14a8\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"y_label\", \"legend\": {\"columns\": 1, \"orient\": \"bottom\"}}, \"x\": {\"type\": \"temporal\", \"field\": \"x\", \"timeUnit\": \"seconds\", \"title\": \"TIME\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"y\", \"scale\": {\"zero\": false}, \"title\": \"NUMBER OF RECORDS CONSUMED / NUMBER OF RECORDS PRODUCED\"}}, \"height\": 300, \"title\": {\"text\": \"IO METRICS of Block: DfFilterNan_1\", \"frame\": \"group\"}, \"width\": 300}], \"resolve\": {\"scale\": {\"color\": \"independent\"}}}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-7f3b5925e6d1317ce15e5ddbaa67e40f\": [{\"y\": 2, \"y_label\": \"NUMBER OF RECORDS CONSUMED\", \"x\": \"0001-01-01T00:00:00.000000\", \"x_label\": \"TIME\", \"x_type\": \"DATE\", \"y_type\": \"FLOAT\"}, {\"y\": 2, \"y_label\": \"NUMBER OF RECORDS CONSUMED\", \"x\": \"0001-01-01T00:00:00.010000\", \"x_label\": \"TIME\", \"x_type\": \"DATE\", \"y_type\": \"FLOAT\"}, {\"y\": 2, \"y_label\": \"NUMBER OF RECORDS CONSUMED\", \"x\": \"0001-01-01T00:00:00.016000\", \"x_label\": \"TIME\", \"x_type\": \"DATE\", \"y_type\": \"FLOAT\"}], \"data-3528bdcb9f69fa18254afa03aa62cc15\": [{\"y\": 2, \"y_label\": \"NUMBER OF RECORDS CONSUMED\", \"x\": \"0001-01-01T00:00:00.000000\", \"x_label\": \"TIME\", \"x_type\": \"DATE\", \"y_type\": \"FLOAT\"}, {\"y\": 2, \"y_label\": \"NUMBER OF RECORDS PRODUCED\", \"x\": \"0001-01-01T00:00:00.029000\", \"x_label\": \"TIME\", \"x_type\": \"DATE\", \"y_type\": \"FLOAT\"}, {\"y\": 2, \"y_label\": \"NUMBER OF RECORDS PRODUCED\", \"x\": \"0001-01-01T00:00:00.100000\", \"x_label\": \"TIME\", \"x_type\": \"DATE\", \"y_type\": \"FLOAT\"}], \"data-74f25a3ff4c12b9051d5a4e07e339b7b\": [{\"y\": 91, \"y_label\": \"NUMBER OF RECORDS PRODUCED\", \"x\": \"0001-01-01T00:00:00.000000\", \"x_label\": \"TIME\", \"x_type\": \"DATE\", \"y_type\": \"FLOAT\"}], \"data-69317bbe25ddebac43f53e65c89529d0\": [{\"y\": 2, \"y_label\": \"NUMBER OF RECORDS CONSUMED\", \"x\": \"0001-01-01T00:00:00.000000\", \"x_label\": \"TIME\", \"x_type\": \"DATE\", \"y_type\": \"FLOAT\"}, {\"y\": 2, \"y_label\": \"NUMBER OF RECORDS PRODUCED\", \"x\": \"0001-01-01T00:00:00.013000\", \"x_label\": \"TIME\", \"x_type\": \"DATE\", \"y_type\": \"FLOAT\"}], \"data-707ac9f36a02a20861217fdba6fc14a8\": [{\"y\": 91, \"y_label\": \"NUMBER OF RECORDS CONSUMED\", \"x\": \"0001-01-01T00:00:00.000000\", \"x_label\": \"TIME\", \"x_type\": \"DATE\", \"y_type\": \"FLOAT\"}, {\"y\": 2, \"y_label\": \"NUMBER OF RECORDS PRODUCED\", \"x\": \"0001-01-01T00:00:00.713000\", \"x_label\": \"TIME\", \"x_type\": \"DATE\", \"y_type\": \"FLOAT\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_pipeline.metrics().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running inference\n",
    "\n",
    "#### Problem \n",
    "Load the saved model and predict on test data and save the results\n",
    "\n",
    "#### Solution\n",
    "Create an inference pipeline, to predict on test data\n",
    "1. Create an instance of `LogisticRegression` class with following parameters and evaluate the model by running execute():\n",
    "    * `operation` - `predict`\n",
    "    * `x_data` - Test data on which the model is to be predicted.\n",
    "    * `attribute` - Column name for the predicted value.\n",
    "    * `path` - Specify the path where the trained model is saved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_predict = (LogisticRegression()\n",
    "         .operation(\"predict\")\n",
    "         .x_data(train_data.out_x)\n",
    "         .attribute(\"classes_\")\n",
    "         .path(\"lr_m1.sav\"))\n",
    "\n",
    "@inputs.atomic.generic(\"output_path\", required=True)\n",
    "@inputs.atomic.generic(\"numpy_array\", required=True)\n",
    "class NumpyToCsv(Block):\n",
    "    def run(self, numpy_array, output_path):\n",
    "        pd.DataFrame(numpy_array,columns=['Predictions']).to_csv(output_path)\n",
    "        \n",
    "csv_writer = (NumpyToCsv()\n",
    "    .output_path(\"/myspace/data/lr_pred_1.csv\")\n",
    "    .numpy_array(lr_model_predict.predictions))\n",
    "\n",
    "predict_pipeline = Pipeline(targets=[csv_writer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_pipeline.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Run the inference pipeline in local </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_pipeline.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Run the inference pipeline in Engine </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from razor.platform import engines\n",
    "\n",
    "deployed_predict_pipeline = engines(name='Engine-1').deploy(pipeline=predict_pipeline)\n",
    "running_predict_pipeline = deployed_predict_pipeline.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_predict_pipeline.status().__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_predict_pipeline.logs(pretty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_predict_pipeline.metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of Logistic Regression model\n",
    "\n",
    "#### Problem\n",
    "The user wants evaluate the logistic regression model that is trained and saved with given metric.\n",
    "#### Solution\n",
    "The evaluation of the classification model comprises following parameters:\n",
    "\n",
    "1. Create an instance of `LogisticRegression` class with following parameters and evaluate the model by running execute():\n",
    "    * `operation` - `evaluate`\n",
    "    * `metric_function` - Specify suitable evaluation metric from the folloeing, that best suits for the problem that you are dealing with.\n",
    "         `confusion_matrix`, `accuracy_score`, `precision_score`, `recall_score`, `f1_score`, `roc_curve`  \n",
    "    * `test_x_data` - Test data on which the model is to be evaluated.\n",
    "    * `test_y_data` - Test target values corresponding to each data point in `test_x_data`.\n",
    "    * `path` - Specify the path where the trained model is saved.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_conf = (LogisticRegression()\n",
    "         .operation(\"evaluate\")\n",
    "         .metric_function(\"confusion_matrix\")\n",
    "         .test_x_data(train_data.out_x)\n",
    "         .test_y_data(train_data.out_y)\n",
    "         .path(\"/tmp/lr_m1.sav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_pipeline = Pipeline(targets=[lr_model_conf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_pipeline.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_pipeline.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. One can compute multiple metrics by passing a list of metrics for the parameter metric_function.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_metrc = (LogisticRegression()\n",
    "         .operation(\"evaluate\")\n",
    "         .metric_function([\"f1_score\",\"precision_score\",\"accuracy_score\",\"recall_score\"])\n",
    "         .test_x_data(train_data.out_x)\n",
    "         .test_y_data(train_data.out_y)\n",
    "         .path(\"/tmp/lr_m1.sav\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_pipeline = Pipeline(targets=[lr_model_metrc])\n",
    "evaluate_pipeline.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_pipeline.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
